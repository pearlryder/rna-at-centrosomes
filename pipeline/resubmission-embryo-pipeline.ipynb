{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package import and define parameters\n",
    "\n",
    "Below, you will define the basic parameters for your database and subcellular structures of interest. You will also initialize the tables in your database to hold the data for your objects of interest.\n",
    "\n",
    "In general, the sections of this notebook can be run separately from each other. However, you'll want to update and run the parameter defining cell before jumping ahead to other sections. If you get an error stating that something has not been defined, it means you probably need to return to the parameters cell and run it. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define database and structural information\n",
    "\n",
    "# database info\n",
    "database_name = 'resubmission2'\n",
    "db_user = \"pearlryder\"\n",
    "db_password = \"\"\n",
    "db_host = \"localhost\"\n",
    "\n",
    "# path to find data\n",
    "\n",
    "USER_NAME = 'pearlryder'\n",
    "FILE_PATH = '/Users/pearlryder/data/resubmission-analysis-2/data'\n",
    "\n",
    "# Subcellular structures of interest. We recommend keeping all names in letters only \n",
    "# and avoiding upper-case letters. You should keep your smFISH images named 'rna'\n",
    "# These names should match the sub-folders in your data folder\n",
    "structures = ['rna', 'centrosomes']\n",
    "\n",
    "\n",
    "# Each structure folder should have two sub-folders, 'raw-data' and 'segmentations'\n",
    "# You can use different names for these folders if you like -- but update the variables below \n",
    "# if you do\n",
    "\n",
    "raw_data_dir = 'raw-data'\n",
    "segmentation_dir = 'segmentations'\n",
    "\n",
    "# If your segmentation files have a different suffix than your raw data files, \n",
    "# update the variable below with the suffix\n",
    "# The suffix below is the suffix that is generated by the Allen Cell Segmenter batch segmentation process\n",
    "# If your segmentation files have the same suffix as your raw data filenames, then change this variable \n",
    "# to an empty string, e.g. segmentation_file_suffix = ''\n",
    "\n",
    "segmentation_file_suffix = ''\n",
    "\n",
    "\n",
    "# Update the scale parameters below for the number of microns per pixel in the xy plane and the z plane\n",
    "xy_scale = 0.065 # microns per pixel in the xy dimension\n",
    "z_scale = 0.25   # microns between each z step\n",
    "\n",
    "\n",
    "# here you can create a distance threshold that changes with the nuclear cycle\n",
    "# the expectation is that you have a column in your images table describing the nuclear stage \n",
    "# this threshold is optional and describes how close an RNA object can be to your target of interest\n",
    "# and still be considered a \"true\" RNA object (instead of background)\n",
    "\n",
    "distance_threshold_dict = {\n",
    "'NC10': 10,\n",
    "'NC11': 8,\n",
    "'NC12': 5,\n",
    "'NC13': 4,\n",
    "'NC14': 3\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object data extraction\n",
    "\n",
    "These cells extracts basic data about the subcellular structure objects and insert it into the postgres database.\n",
    "\n",
    "**Note that images are not reprocessed.**\n",
    "\n",
    "If you need to delete object data for a structure in a particular image, use the `delete_data_db(image_name, structure, conn)` function\n",
    "\n",
    "In a new cell, you would run:\n",
    "```bash\n",
    "from pipeline import delete_data_db\n",
    "conn = psycopg2.connect(database=database_name, user=db_user, password=db_password, host=db_host)\n",
    "image_name = ''\n",
    "structure = ''\n",
    "delete_data_db(image_name, structure, conn)\n",
    "conn.close()\n",
    "```\n",
    "Update the image_name and structure variables with the respective image names and structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python package\n",
    "import os\n",
    "import psycopg2\n",
    "\n",
    "# Functions from the pipeline.py module\n",
    "from pipeline import create_postgres_table, test_data_db, extract_object_properties, insert_object_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell creates postgres tables to hold data for the structures of interest\n",
    "# Table names are automatically assigned based on your structures of interest\n",
    "\n",
    "for structure in structures:\n",
    "    create_postgres_table(structure, database_name, db_user, db_password, db_host)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell navigates through the files in your data directories and extracts basic object data such as \n",
    "# area and integrated intensity for each structure \n",
    "\n",
    "for structure in structures:\n",
    "    print(structure)\n",
    "    segmentations_path = os.path.join(FILE_PATH, structure, segmentation_dir)\n",
    "\n",
    "    for seg_img_name in os.listdir(segmentations_path):\n",
    "        if not seg_img_name[0] == '.':\n",
    "\n",
    "            ins_img_name = seg_img_name\n",
    "\n",
    "            if segmentation_file_suffix:\n",
    "                ins_img_name = seg_img_name[0:-(len(segmentation_file_suffix))] + '.tif'\n",
    "\n",
    "            # check if the image has been processed\n",
    "\n",
    "            \n",
    "            if test_data_db(ins_img_name, structure, database_name, db_user, db_password, db_host):\n",
    "                print('{structure} data for {image_name} has already been processed and will not be re-processed'.format(structure=structure, image_name=ins_img_name))\n",
    "\n",
    "            else:\n",
    "                seg_img_path = os.path.join(segmentations_path, seg_img_name)\n",
    "                ins_img_path = os.path.join(FILE_PATH, structure, raw_data_dir, ins_img_name)\n",
    "\n",
    "                # extract the object properties for that image\n",
    "                object_data_list = extract_object_properties(seg_img_path, ins_img_path, ins_img_name, xy_scale, z_scale)\n",
    "\n",
    "                # save data to database\n",
    "                insert_object_data(structure, object_data_list, database_name, db_user, db_password, db_host)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measure distances between two subcellular structures\n",
    "\n",
    "Below, you will define two subcellular structures. Structure 1 is the \"object of interest.\" For a given image, each structure 1 object will be measured for how far it is to each structure 2 object in the same image. The closest structure 2 object will be identified and the distance to that object will be recorded in the database. \n",
    "\n",
    "You will define which objects you are interested in distance measurements for. Do you want to know how far away the RNA is from the closest centrosome, nucleus, etc? If you want to do measure distances from RNA to more than one subcellular object, then you would repeat this process in a separate cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measured distances on local computer using measure_distance.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create images table\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define parameters\n",
    "\n",
    "# path to the directory containing your csv file\n",
    "USER_NAME = 'pearlryder'\n",
    "csv_dirpath = '/Users/pearlryder/data/resubmission-analysis-2/data'\n",
    "\n",
    "\n",
    "# name of your csv file\n",
    "csv_name = 'resubmission-metadata.csv'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "\n",
    "import csv\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import psycopg2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get column names from CSV file\n",
    "csv_filepath = os.path.join(csv_dirpath, csv_name)\n",
    "\n",
    "with open(os.path.join(csv_filepath), 'r') as f:\n",
    "    d_reader = csv.DictReader(f)\n",
    "\n",
    "    #get fieldnames from DictReader object and store in list\n",
    "    column_names = d_reader.fieldnames\n",
    "\n",
    "print(column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_df = pd.read_csv(csv_filepath)\n",
    "\n",
    "csv_file_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to create a new table:\n",
    "# update the column names below to match the column names in your .csv file (printed out above)\n",
    "# if these column names don't match your table columns in the database, then the copy statement below will fail\n",
    "\n",
    "\n",
    "# THIS QUERY NEEDS TO BE EDITED!\n",
    "create_table_query = \"\"\"CREATE TABLE IF NOT EXISTS images (name TEXT NOT NULL,\n",
    "                                                            rna TEXT,\n",
    "                                                            stage TEXT,\n",
    "                                                            cycle TEXT);\"\"\"\n",
    "\n",
    "\n",
    "print(create_table_query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this code runs the query that you edited above. If you get an error that\n",
    "# 'create_table_query' is not defined, then you need to run the cell above\n",
    "\n",
    "conn = psycopg2.connect(database=database_name, user=db_user, password=db_password, host=db_host)\n",
    "\n",
    "cur = conn.cursor()\n",
    "cur.execute(create_table_query)\n",
    "\n",
    "conn.commit()\n",
    "\n",
    "cur.close()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now copy the data in and add an id column\n",
    "\n",
    "copy_query = \"\"\"COPY images\n",
    "            FROM %(csv_filepath)s DELIMITER ',' CSV HEADER;\"\"\"\n",
    "\n",
    "csv = os.path.join(csv_filepath, csv_name)\n",
    "\n",
    "\n",
    "conn = psycopg2.connect(database=database_name, user=db_user, password=db_password, host=db_host)\n",
    "\n",
    "cur = conn.cursor()\n",
    "cur.execute(copy_query, {'csv_filepath': csv_filepath})\n",
    "conn.commit()\n",
    "\n",
    "add_id_column = \"ALTER TABLE images ADD COLUMN IF NOT EXISTS id SERIAL PRIMARY KEY;\"\n",
    "cur.execute(add_id_column)\n",
    "conn.commit()\n",
    "\n",
    "cur.close()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize RNA to estimate number of single molecules per object\n",
    "\n",
    "Here we estimate the number of molecules of RNA per object. We take advantage of the postgres database to calculate the average intensity of a small molecule of RNA (defined by the lower_threshold and upper_threshold parameters). \n",
    "\n",
    "We recommend including a column named 'rna_type' to describe the type of RNA that each image contains. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# name of the table that contains your RNA data. \n",
    "rna_table = 'rna'\n",
    "\n",
    "# the average integrated intensity is calculated for each rna_type\n",
    "rna_type_column = 'rna'\n",
    "\n",
    "# these thresholds identify small objects of RNA using the area feature\n",
    "# of each object\n",
    "lower_threshold = 50\n",
    "upper_threshold = 150\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import psycopg2\n",
    "from psycopg2 import sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first add a column for the normalized intensity data to your structure table of interest\n",
    "\n",
    "\n",
    "add_normalized_col = sql.SQL(\"ALTER TABLE {rna_table} ADD COLUMN IF NOT EXISTS normalized_intensity REAL;\").format(\n",
    "                                    rna_table = sql.Identifier(rna_table))\n",
    "\n",
    "conn = psycopg2.connect(database=database_name, user=db_user, password=db_password, host=db_host)\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.execute(add_normalized_col)\n",
    "conn.commit()\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the RNA types from the database\n",
    "\n",
    "rna_type_query = sql.SQL(\"SELECT DISTINCT ({rna_type_column}) FROM images;\").format(rna_type_column=sql.Identifier(rna_type_column))\n",
    "\n",
    "conn = psycopg2.connect(database=database_name, user=db_user, password=db_password, host=db_host)\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.execute(rna_type_query)\n",
    "rna_types =  [rna_type[0] for rna_type in cur.fetchall()]\n",
    "\n",
    "cur.close()\n",
    "conn.close\n",
    "\n",
    "print('The RNA types in your database are:\\n' + str(rna_types))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this query calculates the average total intensity of objects between the upper and lower thresholds set in the \n",
    "# parameters column. It then divides every value in the total intensity column by this average and sets the \n",
    "# normalized intensity column to this result\n",
    "\n",
    "\n",
    "for rna_type in rna_types:\n",
    "    normalization_sql = sql.SQL(\"\"\"UPDATE {rna_table} \n",
    "    SET normalized_intensity = total_intensity / \n",
    "    (SELECT avg({rna_table}.total_intensity) FROM {rna_table}\n",
    "                                                    INNER JOIN images \n",
    "                                                    ON {rna_table}.name = images.name \n",
    "                                                    WHERE images.{rna_type_column} = %(rna_type)s\n",
    "                                                    AND rna.area >= %(lower_threshold)s\n",
    "                                                    AND rna.area < %(upper_threshold)s) \n",
    "    FROM images \n",
    "    WHERE {rna_table}.name = images.name \n",
    "    AND images.{rna_type_column} = %(rna_type)s \n",
    "    AND rna.area >= %(lower_threshold)s;\"\"\").format(rna_table=sql.Identifier(rna_table),\n",
    "                                                   rna_type_column=sql.Identifier(rna_type_column))\n",
    "    \n",
    "    conn = psycopg2.connect(database=database_name, user=db_user, password=db_password, host=db_host)\n",
    "    cur = conn.cursor()\n",
    "    \n",
    "    cur.execute(normalization_sql, {'rna_type' : rna_type, 'lower_threshold': lower_threshold, 'upper_threshold': upper_threshold})\n",
    "    conn.commit()\n",
    "    cur.close()\n",
    "    conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate cumulative % RNA and % RNA in granules\n",
    "\n",
    "In this section, we calculate the cumulative distribution of RNA relative to the distance from a subcellular structure of interest. As in the distance measurements section, we define structure_1 as the \"object of interest\" (in most cases, this will be your RNA data) and structure_2 as the \"target object.\" \n",
    "\n",
    "This workflow will calculate the % of total RNA and % of total RNA in granules at 0 microns and then at regular intervals defined by the \"step_size\" parameter up to the distance threshold, if you choose to use a distance threshold. For example, if distance_threshold = 5 and the step_size = 0.05, then this code will calculate the % RNA and % RNA in granules at 0, 0.05, 0.10, 0.15 microns, etc., up to 5 microns for each image.\n",
    "\n",
    "If you choose not to define an upper distance threshold, then the % of RNA is calculated at intervals defined by the step size from 0 microns up to the maximum distance_from_structure_2 for each image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# package import\n",
    "import psycopg2\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# local packages\n",
    "from pipeline import calculate_distributions_by_image_per_cycle, save_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define parameters\n",
    "\n",
    "# update the strings that describe your object of interest and target objects\n",
    "structure_1 = 'rna'\n",
    "structure_2 = 'centrosomes'\n",
    "\n",
    "# update the column name in your images table that holds data for your image names\n",
    "image_name_column = 'name'\n",
    "\n",
    "# update the name of the column in your images table that holds the stage data\n",
    "stage_column = 'stage'\n",
    "\n",
    "# the step size between % RNA measurements; in microns\n",
    "step_size = 0.05\n",
    "\n",
    "# parameters for saving data. Default is to save in the directory containing your raw-data\n",
    "# and segmentations in a folder named data within a folder named output \n",
    "\n",
    "csv_output_dir = os.path.join('/Users/pearlryder/data/resubmission-analysis-2', 'output', 'data')\n",
    "\n",
    "print(\"The directory where distribution data will be saved is:\\n\" + csv_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make an output directory if it doesn't already exist\n",
    "\n",
    "if not os.path.isdir(csv_output_dir):\n",
    "    os.makedirs(csv_output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(plots_output_dir):\n",
    "    os.makedirs(plots_output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a thresholds table w/ the for the distance thresholds\n",
    "\n",
    "# only run this once or you'll get duplicate entries\n",
    "\n",
    "create_thresholds_table_sql = \"\"\"CREATE TABLE IF NOT EXISTS thresholds (stage TEXT,\n",
    "                                                                        maximum_distance INT);\"\"\"\n",
    "\n",
    "insert_thresholds_sql = \"\"\"INSERT INTO thresholds (stage, maximum_distance) \n",
    "                            VALUES ('NC10', 10), \n",
    "                                    ('NC11', 8), \n",
    "                                    ('NC12', 5), \n",
    "                                    ('NC13', 4), \n",
    "                                    ('NC14', 3);\"\"\"\n",
    "\n",
    "\n",
    "conn = psycopg2.connect(database=database_name, user=db_user, password=db_password, host=db_host)\n",
    "cur = conn.cursor()\n",
    "    \n",
    "cur.execute(create_thresholds_table_sql)\n",
    "conn.commit()\n",
    "\n",
    "cur.execute(insert_thresholds_sql)\n",
    "conn.commit()\n",
    "\n",
    "cur.close()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the percent of RNA at 0 microns, 0 > RNA <= 1, and > 1 microns\n",
    "# then save this for plotting in Prism\n",
    "\n",
    "\n",
    "distance_data = \"\"\"SELECT rna.name, \n",
    "images.rna,\n",
    "images.stage,\n",
    "images.cycle,\n",
    "sum(CASE WHEN distance_to_centrosomes = 0 THEN normalized_intensity ELSE 0 END) / (sum(CASE WHEN rna.distance_to_centrosomes <= thresholds.maximum_distance THEN normalized_intensity ELSE 0 END)) * 100 as zero_micron,\n",
    "sum(CASE WHEN distance_to_centrosomes > 0 and distance_to_centrosomes <=1 THEN normalized_intensity ELSE 0 END) / (sum(CASE WHEN rna.distance_to_centrosomes <= thresholds.maximum_distance THEN normalized_intensity ELSE 0 END)) * 100  as one_micron, \n",
    "sum(CASE WHEN distance_to_centrosomes > 1 and distance_to_centrosomes <= thresholds.maximum_distance THEN normalized_intensity ELSE 0 END) / (sum(CASE WHEN rna.distance_to_centrosomes <= thresholds.maximum_distance THEN normalized_intensity ELSE 0 END)) * 100 as greater_than_1_micron\n",
    "FROM rna  \n",
    "INNER JOIN images on rna.name = images.name\n",
    "INNER JOIN thresholds on images.stage = thresholds.stage\n",
    "GROUP BY rna.name, images.rna, images.stage, images.cycle;\"\"\"\n",
    "\n",
    "conn = psycopg2.connect(database=database_name, user=db_user, password=db_password, host=db_host)\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.execute(distance_data)\n",
    "distance_data = cur.fetchall()\n",
    "\n",
    "cur.close()\n",
    "conn.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_df = pd.DataFrame(distance_data, columns=['name', 'rna', 'stage', 'cycle','percent_0', 'percent_0_to_1', 'percent_greater_than_1'])\n",
    "\n",
    "save_csv('rna-distance-df.csv', csv_output_dir, distance_df)\n",
    "\n",
    "distance_df.head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stages = ['NC10', 'NC13']\n",
    "\n",
    "for stage in stages:\n",
    "\n",
    "    NC13_df = distance_df.loc[distance_df['stage'] == stage]\n",
    "\n",
    "    NC13_df_melted = pd.melt(NC13_df, id_vars = ['name', 'rna', 'stage', 'cycle'], value_vars = ['percent_0', 'percent_0_to_1', 'percent_greater_than_1'], var_name='volume', value_name='percent')\n",
    "    NC13_df_melted['rna cycle volume'] = NC13_df_melted['rna'] + ' ' + NC13_df_melted['cycle'] + ' ' + NC13_df_melted['volume']\n",
    "    NC13_df_melted.drop(columns = ['name', 'rna', 'stage', 'cycle', 'volume'], inplace=True)\n",
    "    NC13_df_melted.sort_values(by='rna cycle volume', inplace=True, ignore_index=True)\n",
    "\n",
    "    NC13_pivoted = NC13_df_melted.pivot(columns='rna cycle volume', values='percent')\n",
    "\n",
    "    distribution_data_filename = stage +'-percent-data.csv'\n",
    "\n",
    "    save_csv(distribution_data_filename, csv_output_dir, NC13_pivoted)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# code to calculate the percent RNA distribution\n",
    "\n",
    "# select images table column names and images data from database\n",
    "\n",
    "column_name_query = \"SELECT column_name FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = 'images';\"\n",
    "\n",
    "image_name_query = \"SELECT * FROM images;\"\n",
    "\n",
    "conn = psycopg2.connect(database=database_name, user=db_user, password=db_password, host=db_host)\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.execute(column_name_query)\n",
    "column_names =  [column_name[0] for column_name in cur.fetchall()]\n",
    "\n",
    "cur.execute(image_name_query)\n",
    "image_data =  cur.fetchall()\n",
    "\n",
    "cur.close()\n",
    "conn.close\n",
    "\n",
    "# process the images data into format needed for rna_distribution calculation\n",
    "# this will create a list of dictionaries that contain 'column_name' : field\n",
    "# one row is converted into one dictionary in the list\n",
    "\n",
    "image_data_list = []\n",
    "\n",
    "for row_data in image_data:\n",
    "    image_data_dict = {}\n",
    "    \n",
    "    for column_name in column_names:\n",
    "        idx = column_names.index(column_name)\n",
    "        \n",
    "        image_data_dict[column_name] = row_data[idx]\n",
    "        \n",
    "    image_data_list.append(image_data_dict)\n",
    "    \n",
    "print('The names of the columns in your images table are:\\n ' + str(column_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell calculates the percent distribution of total RNA and RNA in granules from 0.0 microns to the \n",
    "# distance threshold specified by the user. The data is contained in a dataframe object \n",
    "\n",
    "conn = psycopg2.connect(database=database_name, user=db_user, password=db_password, host=db_host)\n",
    "\n",
    "%time rna_distribution_df = calculate_distributions_by_image_per_cycle(image_data_list, distance_threshold_dict, step_size, image_name_column, stage_column, structure_1, structure_2, conn)\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell reveals the top of the RNA distribution dataframe\n",
    "# verify that you have the expected columns\n",
    "\n",
    "rna_distribution_df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell saves the distributions data to a file named distributions.csv \n",
    "# in an automatically created \"output/data\" folder in your data folder\n",
    "# you can change the name of the file name in the first line of this cell\n",
    "# this cell WILL NOT overwrite data\n",
    "\n",
    "distribution_data_filename = 'distributions.csv'\n",
    "\n",
    "save_csv(distribution_data_filename, csv_output_dir, rna_distribution_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the percent of RNA IN GRANULES at any distance\n",
    "\n",
    "distance_data = \"\"\"SELECT rna.name, \n",
    "                            images.rna,\n",
    "                            images.stage,\n",
    "                            images.cycle,\n",
    "                            sum(CASE WHEN normalized_intensity >= 4 AND distance_to_centrosomes <= thresholds.maximum_distance THEN normalized_intensity ELSE 0 END) / (sum(CASE WHEN rna.distance_to_centrosomes <= thresholds.maximum_distance THEN normalized_intensity ELSE 0 END)) * 100 as percent_granule\n",
    "                            FROM rna  \n",
    "INNER JOIN images on rna.name = images.name\n",
    "INNER JOIN thresholds on images.stage = thresholds.stage\n",
    "GROUP BY rna.name, images.rna, images.stage, images.cycle;\"\"\"\n",
    "\n",
    "conn = psycopg2.connect(database=database_name, user=db_user, password=db_password, host=db_host)\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.execute(distance_data)\n",
    "granule_data = cur.fetchall()\n",
    "\n",
    "cur.close()\n",
    "conn.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "granule_df = pd.DataFrame(granule_data, columns = ['name', 'rna', 'stage', 'cycle', 'percent_large_granule'])\n",
    "\n",
    "granule_df = granule_df.loc[granule_df['rna'].isin(['cen', 'gapdh'])]\n",
    "\n",
    "save_csv('percent-granule.csv', csv_output_dir, granule_df)\n",
    "\n",
    "\n",
    "granule_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-orient the data to import it into prism\n",
    "\n",
    "stages = ['NC10', 'NC13']\n",
    "\n",
    "for stage in stages:\n",
    "\n",
    "    NC13_df = granule_df.loc[granule_df['stage'] == stage]\n",
    "\n",
    "    NC13_df_melted = pd.melt(NC13_df, id_vars = ['name', 'rna', 'stage', 'cycle'], value_vars = ['percent_large_granule'], var_name='volume', value_name='percent_large_granule')\n",
    "    NC13_df_melted['rna cycle volume'] = NC13_df_melted['rna'] + ' ' + NC13_df_melted['cycle'] + ' ' + NC13_df_melted['volume']\n",
    "    NC13_df_melted.drop(columns = ['name', 'rna', 'stage', 'cycle', 'volume'], inplace=True)\n",
    "    NC13_df_melted.sort_values(by='rna cycle volume', inplace=True, ignore_index=True)\n",
    "\n",
    "    NC13_pivoted = NC13_df_melted.pivot(columns='rna cycle volume', values='percent_large_granule')\n",
    "\n",
    "    granule_mean_filename = stage + 'percent-granule-data-for-prism.csv'\n",
    "\n",
    "    save_csv(granule_mean_filename, csv_output_dir, NC13_pivoted)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph distribution data\n",
    "\n",
    "Here we graph the data that was saved in the previous cell\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# package imports\n",
    "\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "\n",
    "distribution_data_filename = 'distributions.csv'\n",
    "\n",
    "data_output_dir = os.path.join('/Users/' + USER_NAME + '/data/resubmission-analysis-2/', 'output', 'data')\n",
    "\n",
    "plots_output_dir =  os.path.join('/Users/' + USER_NAME + '/data/resubmission-analysis-2/', 'output', 'plots')\n",
    "\n",
    "sns_palette = sns.color_palette()\n",
    "sns.palplot(sns_palette)\n",
    "\n",
    "palette_dict = {'gapdh': sns_palette[1], \n",
    "                'cen': sns_palette[0], \n",
    "                'plp': sns_palette[0],\n",
    "                'cyc B': sns_palette[0],\n",
    "               'pins': sns_palette[0],\n",
    "               'cg14438':sns_palette[0]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we define a function to save your plots. We choose to save at 600 dpi as .pdf files, which work well with\n",
    "# Adobe Illustrator files for figure creation. You can change this function so as desired so that your plots will\n",
    "# be saved consistently\n",
    "\n",
    "def save_plot(plot_fn, plots_output_dir, plot):\n",
    "    \"\"\" This function takes two strings as inputs and a matplotlib plot object. plot_fn describes the desired filename\n",
    "    plots_output_dir is the directory to save the plot. plot is a variable containing your plot\n",
    "    \n",
    "    This function will not overwrite data\n",
    "    \n",
    "    The function tests if a file exists in the plots_output_dir. If a file exists, it prints a message and does nothing\n",
    "    If a file does not a exist, the plot is saved\n",
    "    \n",
    "    Returns nothing\n",
    "    \"\"\"\n",
    "    \n",
    "    if os.path.isfile(plots_output_dir + '/' + plot_fn):\n",
    "        print('Plot already saved and will not be saved again')\n",
    "    else:\n",
    "        plot.savefig(plots_output_dir + '/' + plot_fn, bbox_inches = 'tight', dpi = 600, format = 'pdf', transparent = True)\n",
    "        \n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution_df = pd.read_csv(os.path.join(data_output_dir, distribution_data_filename))\n",
    "\n",
    "distribution_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we plot the % RNA distribution at each distance as mean (dark line) +/- sd (shading) using the Seaborn library and matplotlib\n",
    "# https://seaborn.pydata.org/examples/index.html\n",
    "# There are a lot of options in Seaborn. In this example, we separate the plots into columns based on the variable \n",
    "# \"cycle\" and adjust the color using the rna_type, in order to compare our experimental RNA (cen) to control (gapdh)\n",
    "\n",
    "\n",
    "sns.set_style(\"ticks\")\n",
    "sns.set_context(\"paper\")\n",
    "fractions_structure_1_plt = sns.relplot(x = 'distance', \n",
    "                                        y = 'percent_total_rna', \n",
    "                                        hue = 'rna', \n",
    "                                        col = 'cycle', \n",
    "                                        row = 'stage',\n",
    "                                        col_order = ['interphase', 'metaphase'], \n",
    "                                        ci = \"sd\", \n",
    "                                        kind=\"line\", \n",
    "                                        data = distribution_df);\n",
    "\n",
    "plt.xlim(0)\n",
    "plt.ylim(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_plot(rna_dataframe, y_axis, labels_bool):\n",
    "    sns.set_style(\"ticks\")\n",
    "    sns.set_context(\"paper\")\n",
    "    line_plt = sns.relplot(x = 'distance', \n",
    "                                  y = y_axis, \n",
    "                                  hue = 'rna', \n",
    "                                  palette = palette_dict,\n",
    "                                  col = 'cycle', \n",
    "                                  col_order = ['interphase', 'metaphase'], \n",
    "                                  ci = \"sd\", \n",
    "                                  kind=\"line\", \n",
    "                                  data = rna_dataframe);\n",
    "\n",
    "    plt.xlim(0)\n",
    "    plt.ylim(0,100)\n",
    "    \n",
    "    if not labels_bool:\n",
    "        for ax in line_plt.axes.flatten():\n",
    "            ax.xaxis.set_ticklabels([])\n",
    "            ax.yaxis.set_ticklabels([])\n",
    "            ax.set_ylabel('')\n",
    "            ax.set_xlabel('')\n",
    "            ax.set_title('')\n",
    "    \n",
    "    return line_plt\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we plot the distribution as mean (dark line) +/- sd (shading) using the Seaborn library and matplotlib\n",
    "# https://seaborn.pydata.org/examples/index.html\n",
    "# There are a lot of options in Seaborn. In this example, we separate the plots into columns based on the variable \n",
    "# \"cycle\" and adjust the color using the rna_type, in order to compare our experimental RNA (cen) to control (gapdh)\n",
    "\n",
    "\n",
    "rna_types = ['cen', 'plp', 'cg14438', 'pins', 'cyc B']\n",
    "\n",
    "stages = ['NC10', 'NC13']\n",
    "\n",
    "for stage in stages:\n",
    "    \n",
    "    if stage == 'NC10':\n",
    "        rna_types = ['cen']\n",
    "        \n",
    "    else:\n",
    "        rna_types = ['cen', 'plp', 'cg14438', 'pins', 'cyc B']\n",
    "    \n",
    "    stage_df = rna_distribution_df.loc[rna_distribution_df['stage'] == stage]\n",
    "\n",
    "    for rna_type in rna_types:\n",
    "        gapdh_data = stage_df.loc[stage_df['rna'] == 'gapdh'] \n",
    "\n",
    "        rna_data = stage_df.loc[stage_df['rna'] == rna_type] \n",
    "\n",
    "        # subset dataframes\n",
    "        combined_data = pd.concat([rna_data, gapdh_data])\n",
    "        less_than_1_micron_distribution_df = combined_data.loc[combined_data['distance'] <= 1] \n",
    "\n",
    "        # combine into list of dictionaries\n",
    "        dataframes = [('_all-data',  combined_data), ('_less-than-1', less_than_1_micron_distribution_df)]\n",
    "\n",
    "        labels_bool_tuple = (True, False)\n",
    "\n",
    "        y_axis_tuple = ('percent_total_rna',)\n",
    "\n",
    "        for y_axis in y_axis_tuple:\n",
    "            for (data_type, rna_dataframe) in dataframes:\n",
    "                for labels_bool in labels_bool_tuple:\n",
    "\n",
    "                    if labels_bool == True:\n",
    "                        label = '_labels_'\n",
    "                    else:\n",
    "                        label = '_no_labels_'\n",
    "\n",
    "                    rna_plt = line_plot(rna_dataframe, y_axis, labels_bool)\n",
    "                    fn = rna_type + '_' + stage + data_type + label + y_axis + '.pdf'\n",
    "                    save_plot(fn, plots_output_dir, rna_plt)\n",
    "                    plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save database tables as .csv files\n",
    "\n",
    "This section gives you the option to save your database tables as .csv files, which allows you to view raw object data using a text editor rather than needing to have a specialized program like postgres.\n",
    "\n",
    "By default, the data will be saved in the output/db_backups/db_csvs folder. You can change this behavior in the parameters cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# package import\n",
    "\n",
    "import psycopg2\n",
    "from psycopg2 import sql \n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters \n",
    "\n",
    "db_csv_output_dir =  os.path.join(FILE_PATH, 'output', 'db_backups', 'db_csvs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make folders to contain csv files if they do not already exist \n",
    "\n",
    "if not os.path.isdir(db_csv_output_dir):\n",
    "    os.makedirs(db_csv_output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell gets the names of the tables you created from the postgres database\n",
    "\n",
    "select_tables_sql = \"SELECT table_name FROM information_schema.tables WHERE table_schema = 'public';\"\n",
    "\n",
    "conn = psycopg2.connect(database=database_name, user=db_user, password=db_password, host=db_host)\n",
    "cur = conn.cursor()\n",
    "cur.execute(select_tables_sql)\n",
    "table_name_raw = cur.fetchall()\n",
    "cur.close()\n",
    "conn.close()\n",
    "\n",
    "table_names = [table_name[0] for table_name in table_name_raw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell copies data from those tables into csv files\n",
    "# it will overwrite your previously saved files\n",
    "\n",
    "for table_name in table_names:\n",
    "    table_fn = table_name + '.csv'\n",
    "    table_path = os.path.join(db_csv_output_dir, table_fn)\n",
    "\n",
    "    copy_sql_query = sql.SQL(\"COPY {table_name} TO STDOUT WITH CSV HEADER\").format(table_name = sql.Identifier(table_name))\n",
    "\n",
    "    conn = psycopg2.connect(database=database_name, user=db_user, password=db_password, host=db_host)\n",
    "    cur = conn.cursor()\n",
    "\n",
    "\n",
    "    with open(table_path, 'w') as f_output:\n",
    "        cur.copy_expert(copy_sql_query, f_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
